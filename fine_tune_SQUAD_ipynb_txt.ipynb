{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maoussy/prj3/blob/master/fine_tune_SQUAD_ipynb_txt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "narrative-warner",
      "metadata": {
        "id": "narrative-warner"
      },
      "source": [
        "# Fine-Tuning With SQuAD 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "theoretical-confirmation",
      "metadata": {
        "id": "theoretical-confirmation"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "promising-stocks",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "promising-stocks",
        "outputId": "fe0599a2-87df-4bb9-9c74-8971b6c1f783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘squad’: File exists\n",
            "--2023-03-20 20:05:11--  https://raw.githubusercontent.com/chiahsuan156/Spoken-SQuAD/master/spoken_train-v1.1.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21805612 (21M) [text/plain]\n",
            "Saving to: ‘squad/train-v2.0.json’\n",
            "\n",
            "squad/train-v2.0.js 100%[===================>]  20.79M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-03-20 20:05:11 (146 MB/s) - ‘squad/train-v2.0.json’ saved [21805612/21805612]\n",
            "\n",
            "--2023-03-20 20:05:11--  https://raw.githubusercontent.com/chiahsuan156/Spoken-SQuAD/master/spoken_test-v1.1_WER54.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3370853 (3.2M) [text/plain]\n",
            "Saving to: ‘squad/dev-v2.0.json’\n",
            "\n",
            "squad/dev-v2.0.json 100%[===================>]   3.21M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-03-20 20:05:11 (47.0 MB/s) - ‘squad/dev-v2.0.json’ saved [3370853/3370853]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir squad\n",
        "!wget https://raw.githubusercontent.com/chiahsuan156/Spoken-SQuAD/master/spoken_train-v1.1.json  -O squad/train-v2.0.json\n",
        "!wget https://raw.githubusercontent.com/chiahsuan156/Spoken-SQuAD/master/spoken_test-v1.1_WER54.json -O squad/dev-v2.0.json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beautiful-composition",
      "metadata": {
        "id": "beautiful-composition"
      },
      "source": [
        "---\n",
        "# Get and Prepare Data\n",
        "\n",
        "## Download SQuAD data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "laughing-novel",
      "metadata": {
        "id": "laughing-novel"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "progressive-spice",
      "metadata": {
        "id": "progressive-spice"
      },
      "outputs": [],
      "source": [
        "\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fleet-rolling",
      "metadata": {
        "id": "fleet-rolling"
      },
      "source": [
        "## Read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "touched-terry",
      "metadata": {
        "id": "touched-terry"
      },
      "outputs": [],
      "source": [
        "def read_squad(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    # initialize lists for contexts, questions, and answers\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    # iterate through all data in squad data\n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                if 'plausible_answers' in qa.keys():\n",
        "                    access = 'plausible_answers'\n",
        "                else:\n",
        "                    access = 'answers'\n",
        "                for answer in qa['answers']:\n",
        "                    # append data to lists\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "    # return formatted data lists\n",
        "    return contexts, questions, answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "little-treasury",
      "metadata": {
        "id": "little-treasury"
      },
      "outputs": [],
      "source": [
        "train_contexts, train_questions, train_answers = read_squad('/content/squad/train-v2.0.json')\n",
        "test_contexts, test_questions, test_answers = read_squad('/content/squad/dev-v2.0.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "handed-zealand",
      "metadata": {
        "id": "handed-zealand"
      },
      "source": [
        "## Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "precious-windows",
      "metadata": {
        "id": "precious-windows"
      },
      "outputs": [],
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    # loop through each answer-context pair\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        # gold_text refers to the answer we are expecting to find in context\n",
        "        gold_text = answer['text']\n",
        "        # we already know the start index\n",
        "        start_idx = answer['answer_start']\n",
        "        # and ideally this would be the end index...\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # ...however, sometimes squad answers are off by a character or two\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            # if the answer is not off :)\n",
        "            answer['answer_end'] = end_idx\n",
        "        else:\n",
        "            for n in [1, 2]:\n",
        "                if context[start_idx-n:end_idx-n] == gold_text:\n",
        "                    # this means the answer is off by 'n' tokens\n",
        "                    answer['answer_start'] = start_idx - n\n",
        "                    answer['answer_end'] = end_idx - n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "detailed-karen",
      "metadata": {
        "id": "detailed-karen"
      },
      "outputs": [],
      "source": [
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(test_answers, test_contexts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cheap-pharmacology",
      "metadata": {
        "id": "cheap-pharmacology"
      },
      "source": [
        "## Encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "voluntary-effect",
      "metadata": {
        "id": "voluntary-effect"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(train_encodings['input_ids'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "t4Isf-FZOUuP",
        "outputId": "af514622-dfe3-424b-f175-bfa2c4d0f37f"
      },
      "id": "t4Isf-FZOUuP",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] architecturally the school has a catholic character. atop the main building school dome is the golden statue of the virgin mary. immediately in front of the main building in facing it is a copper statue of christ with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen fifty eight. at the end of the main drive and in a direct line that connects through three statues in the gold dome is as simple modern stone statue of mary. [SEP] what is in front of the notre dame main building? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_encodings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGIoWw71rw0I",
        "outputId": "967e12e8-2b82-4e63-f811-9ef5fbcb3811"
      },
      "id": "TGIoWw71rw0I",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "behind-technician",
      "metadata": {
        "id": "behind-technician"
      },
      "outputs": [],
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    \n",
        "    count = 0\n",
        "    \n",
        "    for i in range(len(answers)):\n",
        "        start_positions.append(encodings[i].char_to_token(answers[i]['answer_start']))\n",
        "        end_positions.append(encodings[i].char_to_token(answers[i]['answer_end']))\n",
        "        \n",
        "        # if start position is None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "            \n",
        "        # if end position is None, the 'char_to_token' function points to space after the correct token, so add -1\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = encodings[i].char_to_token(answers[i]['answer_end'] - 1)\n",
        "            \n",
        "            # if end position is still None, the answer passage has been truncated\n",
        "            if end_positions[-1] is None:\n",
        "                count += 1\n",
        "                end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "    print(count)\n",
        "\n",
        "  # Update the data in dictionary\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "    add_token_positions(train_encodings, train_answers)\n",
        "    add_token_positions(test_encodings, test_answers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "specified-daughter",
      "metadata": {
        "id": "specified-daughter"
      },
      "source": [
        "---\n",
        "\n",
        "# PyTorch Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "recognized-proceeding",
      "metadata": {
        "id": "recognized-proceeding"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(test_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "alive-qatar",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "44d4aef12c6c43b983ccbef7bd72eebf",
            "6db322ad4ba74b4c83f7179363f4fac8",
            "6f666db5dcad4aaa8aa1fbd1203fe471",
            "4c0b1b8f575c46e29abe114c57e48b05",
            "8f575b63dfb947648b9a25475a322cd2",
            "cea7435852754ef89e42b9c5ff6e3452",
            "150ead838711408d991280530a82487d",
            "a7a6e70dc4a84ec2bd32bf516ea5aa29",
            "d63b93af52ee47d49bc4e84f6ca5e15d",
            "3b3d671049fc4ffeac4195c7c046f239",
            "13a51b73041a428cba76b4fef9989c0e"
          ]
        },
        "id": "alive-qatar",
        "outputId": "f539b629-083e-4ed1-8027-92f9e3296275"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44d4aef12c6c43b983ccbef7bd72eebf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertForQuestionAnswering\n",
        "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "spectacular-course",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spectacular-course",
        "outputId": "3c2a09e6-bd6a-41de-fe4a-fbba3669c69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 0: 100%|██████████| 2320/2320 [30:51<00:00,  1.25it/s, loss=2.18]\n",
            "Epoch 1: 100%|██████████| 2320/2320 [30:48<00:00,  1.25it/s, loss=1.02]\n",
            "Epoch 2: 100%|██████████| 2320/2320 [30:47<00:00,  1.26it/s, loss=1.75]\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# setup GPU/CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# move model over to detected device\n",
        "model.to(device)\n",
        "# activate training mode of model\n",
        "model.train()\n",
        "# initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# initialize data loader for training data\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "    # setup loop (we use tqdm for the progress bar)\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        # initialize calculated gradients (from prev step)\n",
        "        optim.zero_grad()\n",
        "        # pull all the tensor batches required for training\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        # train model on batch and return outputs (incl. loss)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                        start_positions=start_positions,\n",
        "                        end_positions=end_positions)\n",
        "        # extract loss\n",
        "        loss = outputs[0]\n",
        "        # calculate loss for every parameter that needs grad update\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optim.step()\n",
        "        # print relevant info to progress bar\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "proper-recruitment",
      "metadata": {
        "id": "proper-recruitment"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "severe-brooks",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "severe-brooks",
        "outputId": "e66b2970-0ce7-4e62-c8bb-87a8fde7ef0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('models/distilbert-custom/tokenizer_config.json',\n",
              " 'models/distilbert-custom/special_tokens_map.json',\n",
              " 'models/distilbert-custom/vocab.txt',\n",
              " 'models/distilbert-custom/added_tokens.json',\n",
              " 'models/distilbert-custom/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model_path = 'models/distilbert-custom'\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "otherwise-religion",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otherwise-religion",
        "outputId": "70e05269-6b1f-47bc-b026-f1df3595ae1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1116/1116 [05:10<00:00,  3.59it/s]\n"
          ]
        }
      ],
      "source": [
        "# switch model out of training mode\n",
        "model.eval()\n",
        "\n",
        "#val_sampler = SequentialSampler(val_dataset)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "acc = []\n",
        "\n",
        "# initialize loop for progress bar\n",
        "loop = tqdm(val_loader)\n",
        "# loop through batches\n",
        "for batch in loop:\n",
        "    # we don't need to calculate gradients as we're not training\n",
        "    with torch.no_grad():\n",
        "        # pull batched items from loader\n",
        "        \n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_true = batch['start_positions'].to(device)\n",
        "        end_true = batch['end_positions'].to(device)\n",
        "        # make predictions\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "        # pull preds out\n",
        "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "        # calculate accuracy for both and append to accuracy list\n",
        "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
        "# calculate average accuracy in total\n",
        "acc = sum(acc)/len(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "pressed-request",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "pressed-request",
        "outputId": "11e8bf3c-cc5d-46f1-932b-0ccd1fd074a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T/F\tstart\tend\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-e54ba63f2947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"T/F\\tstart\\tend\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n\u001b[1;32m      4\u001b[0m           f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")\n",
            "\u001b[0;31mNameError\u001b[0m: name 'start_true' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"T/F\\tstart\\tend\\n\")\n",
        "for i in range(len(start_true)):\n",
        "    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
        "          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44d4aef12c6c43b983ccbef7bd72eebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6db322ad4ba74b4c83f7179363f4fac8",
              "IPY_MODEL_6f666db5dcad4aaa8aa1fbd1203fe471",
              "IPY_MODEL_4c0b1b8f575c46e29abe114c57e48b05"
            ],
            "layout": "IPY_MODEL_8f575b63dfb947648b9a25475a322cd2"
          }
        },
        "6db322ad4ba74b4c83f7179363f4fac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea7435852754ef89e42b9c5ff6e3452",
            "placeholder": "​",
            "style": "IPY_MODEL_150ead838711408d991280530a82487d",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "6f666db5dcad4aaa8aa1fbd1203fe471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a6e70dc4a84ec2bd32bf516ea5aa29",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d63b93af52ee47d49bc4e84f6ca5e15d",
            "value": 267967963
          }
        },
        "4c0b1b8f575c46e29abe114c57e48b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b3d671049fc4ffeac4195c7c046f239",
            "placeholder": "​",
            "style": "IPY_MODEL_13a51b73041a428cba76b4fef9989c0e",
            "value": " 268M/268M [00:04&lt;00:00, 55.5MB/s]"
          }
        },
        "8f575b63dfb947648b9a25475a322cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea7435852754ef89e42b9c5ff6e3452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "150ead838711408d991280530a82487d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7a6e70dc4a84ec2bd32bf516ea5aa29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63b93af52ee47d49bc4e84f6ca5e15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b3d671049fc4ffeac4195c7c046f239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a51b73041a428cba76b4fef9989c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}